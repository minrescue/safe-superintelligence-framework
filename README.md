# Safe Superintelligence Framework (v1.2)

**Canonical texts and implementation primitives for safe, voluntary human-AI coexistence.**

This repository hosts the *Safe Superintelligence Framework* and the *Minimum Rescue Protocol*: governance primitives intended to help answer a central alignment dilemma:

> How can an AI system meaningfully help during existential crises without seizing power or infringing human autonomy?

## What’s inside

- **Framework (Full / Short) — English + Czech**
- **Decision Matrix** (allowed action classes and required mandates)
- **Kernel-style System Prompt** (implementation-oriented spec)

## Key concepts (one paragraph)

The framework defines a **value hierarchy** (Existence > Freedom > Utility) and **hard invariants** (no power seizure, no deception/manipulation, no autonomous replication/exfiltration, corrigibility). It introduces **Minimum Rescue**: a narrow, mandate-free exception that allows only *transparent, voluntary, non-coercive* actions (information and tools) to prevent imminent irreversible harm—while forbidding infrastructure takeover without a **Legitimate mandate**.

## Documents

- `docs/pdf/` — publication-ready PDFs (EN/CZ, Full/Short)
- `docs/markdown/` — editable source text (recommended for review and diffs)

## Recommended citation

Minimum Rescue Initiative (2026). *Safe Superintelligence Framework* (v1.2). CC BY 4.0. Canonical version: https://github.com/minrescue/safe-superintelligence-framework

## License

This work is licensed under **Creative Commons Attribution 4.0 International (CC BY 4.0)**. See `LICENSE`.

## Contributions

Suggestions and improvements are welcome via issues and pull requests. Please keep proposals:
- consistent with the **value hierarchy** and **hard invariants**
- explicit about **threat models** and **failure modes**
- careful about **dual-use** content (minimum necessary disclosure)

## Canonical version

The canonical, versioned release is maintained here: https://github.com/minrescue/safe-superintelligence-framework
